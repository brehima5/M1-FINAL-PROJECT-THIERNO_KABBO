{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d327cdad",
   "metadata": {},
   "source": [
    "# Café Sales Data Analysis - Business Intelligence Report\n",
    "\n",
    "## Executive Summary\n",
    "This notebook provides a comprehensive analysis of café sales data to help the café owner make data-driven decisions for marketing campaigns and operational improvements. We analyze 10,000 transactions from 2023 to identify peak business periods, customer preferences, and revenue optimization opportunities.\n",
    "\n",
    "## Business Objectives\n",
    "1. **Analyze popular selling times**: \n",
    "- When are the busiest AND most profitable times?\n",
    "- Are weekends busier than weekdays?\n",
    "2. **Understand Customer Behavior**: What items do customers spend most on?\n",
    "3. **Optimize Operations**: Which payment methods and locations drive the most revenue?\n",
    "4. **Data Quality Assessment**: What issues exist in our transaction data?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74cfeff",
   "metadata": {},
   "source": [
    "1. Data Import, Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29316201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00c3d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows:\n",
      "Transaction Date\n",
      "2023-02-06    40\n",
      "2023-06-16    40\n",
      "2023-03-13    39\n",
      "2023-07-21    39\n",
      "2023-09-21    39\n",
      "              ..\n",
      "2023-04-27    15\n",
      "2023-11-24    15\n",
      "2023-03-11    14\n",
      "2023-02-17    14\n",
      "2023-07-22    14\n",
      "Name: count, Length: 365, dtype: int64\n",
      "Dataset shape: (10000, 8)\n",
      "Total transactions: 10,000\n"
     ]
    }
   ],
   "source": [
    "#The na_values replaces all the unknown and error values to NaN\n",
    "df = pd.read_csv('/Users/kabbo/Desktop/marcy/Project 2 Cafe Sales/M1-FINAL-PROJECT-THIERNO_KABBO/data/raw/cafe_sales.csv', na_values=[\"UNKNOWN\", \"ERROR\", \"\"])\n",
    "\n",
    "\n",
    "#df = pd.read_csv('/Users/kabbo/Desktop/marcy/Project 2 Cafe Sales/M1-FINAL-PROJECT-THIERNO_KABBO/data/raw/cafe_sales.csv')\n",
    "\n",
    "\n",
    "# Look at first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df[\"Transaction Date\"].value_counts())\n",
    "\n",
    "# Get basic information\n",
    "print(f\"Dataset shape: {df.shape}\")  # (rows, columns)\n",
    "print(f\"Total transactions: {df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b0851f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item\n",
      "Juice       1171\n",
      "Coffee      1165\n",
      "Salad       1148\n",
      "Cake        1139\n",
      "Sandwich    1131\n",
      "Smoothie    1096\n",
      "Cookie      1092\n",
      "Tea         1089\n",
      "UNKNOWN      969\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Item'] = df['Item'].fillna('UNKNOWN')\n",
    "\n",
    "#print(df['Item'].isnull().sum())  # Should print 0\n",
    "#print(df['Item'].unique())        # Should include 'UNKNOWN' in place of NaN before\n",
    "print(df['Item'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5546ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types and missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Transaction ID    10000 non-null  object \n",
      " 1   Item              10000 non-null  object \n",
      " 2   Quantity          9521 non-null   float64\n",
      " 3   Price Per Unit    9467 non-null   float64\n",
      " 4   Total Spent       9498 non-null   float64\n",
      " 5   Payment Method    6822 non-null   object \n",
      " 6   Location          6039 non-null   object \n",
      " 7   Transaction Date  9540 non-null   object \n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 625.1+ KB\n",
      "\n",
      "Column data types:\n",
      "  • Transaction ID: object\n",
      "  • Item: object\n",
      "  • Quantity: float64\n",
      "  • Price Per Unit: float64\n",
      "  • Total Spent: float64\n",
      "  • Payment Method: object\n",
      "  • Location: object\n",
      "  • Transaction Date: object\n"
     ]
    }
   ],
   "source": [
    "# Get detailed information about each column\n",
    "print(\"Data types and missing values:\")\n",
    "df.info()\n",
    "\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nColumn data types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  • {col}: {df[col].dtype}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3497f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values per column:\n",
      "  • Transaction ID: 10,000 unique values\n",
      "  • Item: 9 unique values\n",
      "  • Quantity: 5 unique values\n",
      "  • Price Per Unit: 6 unique values\n",
      "  • Total Spent: 17 unique values\n",
      "  • Payment Method: 3 unique values\n",
      "  • Location: 2 unique values\n",
      "  • Transaction Date: 365 unique values\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in each column\n",
    "print(\"\\nUnique values per column:\")\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"  • {col}: {unique_count:,} unique values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93d1b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values analysis:\n",
      "                  Missing Count  Missing Percentage\n",
      "Transaction ID                0                0.00\n",
      "Item                          0                0.00\n",
      "Quantity                    479                4.79\n",
      "Price Per Unit              533                5.33\n",
      "Total Spent                 502                5.02\n",
      "Payment Method             3178               31.78\n",
      "Location                   3961               39.61\n",
      "Transaction Date            460                4.60\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values analysis:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent.round(2)\n",
    "})\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fae47c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "Empty DataFrame\n",
      "Columns: [Transaction ID, Item, Quantity, Price Per Unit, Total Spent, Payment Method, Location, Transaction Date]\n",
      "Index: []\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "#Checking for duplicates\n",
    "\n",
    "duplicate_rows = df[df.duplicated(subset=['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Transaction Date'], keep=False)]\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)\n",
    "\n",
    "num_duplicates = df.duplicated(subset=['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Transaction Date'], keep=False).sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52e7fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/78/8f22v_ln4kvg9b_7fr3_2nfh0000gn/T/ipykernel_33765/2137753788.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Quantity'].fillna(quantity_median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Imputing each column depending on skew results that we got from Excel (Thierno will explain this)\n",
    "\n",
    "# We will use Average for Quantity column\n",
    "# Calculate the mean of the 'Quantity' column, ignoring NaN values\n",
    "quantity_median = df['Quantity'].median()\n",
    "# Impute the NaN values in 'Quantity' with the calculated mean\n",
    "df['Quantity'].fillna(quantity_median, inplace=True)\n",
    "\n",
    "df['Quantity'] = df['Quantity'].astype(int)\n",
    "#print(df['Quantity'].head())\n",
    "\n",
    "print((df['Quantity'].sum()))  # Prints 0 which means no erros or unknowns\n",
    "#print(quantity_median)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c69d97f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/78/8f22v_ln4kvg9b_7fr3_2nfh0000gn/T/ipykernel_33765/3480734360.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Price Per Unit'].fillna(pricer_per_unit_mean, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# There is no skew on the Price Per Unit column so we will just use average\n",
    "pricer_per_unit_mean = df['Price Per Unit'].mean()\n",
    "\n",
    "df['Price Per Unit'].fillna(pricer_per_unit_mean, inplace=True)\n",
    "\n",
    "#print((df['Price Per Unit'].mean())) \n",
    "\n",
    "#print((df['Price Per Unit'].sum())) \n",
    "#print(df['Price Per Unit'].isnull().sum())  # Prints 0 which means no erros or unknowns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5441459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction ID      Item  Quantity  Price Per Unit  Total Spent  \\\n",
      "0    TXN_1961373    Coffee         2             2.0          4.0   \n",
      "1    TXN_4977031      Cake         4             3.0         12.0   \n",
      "2    TXN_4271903    Cookie         4             1.0          4.0   \n",
      "3    TXN_7034554     Salad         2             5.0         10.0   \n",
      "4    TXN_3160411    Coffee         2             2.0          4.0   \n",
      "5    TXN_2602893  Smoothie         5             4.0         20.0   \n",
      "6    TXN_4433211   UNKNOWN         3             3.0          9.0   \n",
      "7    TXN_6699534  Sandwich         4             4.0         16.0   \n",
      "8    TXN_4717867   UNKNOWN         5             3.0         15.0   \n",
      "9    TXN_2064365  Sandwich         5             4.0         20.0   \n",
      "\n",
      "   Payment Method  Location Transaction Date  \n",
      "0     Credit Card  Takeaway       2023-09-08  \n",
      "1            Cash  In-store       2023-05-16  \n",
      "2     Credit Card  In-store       2023-07-19  \n",
      "3             NaN       NaN       2023-04-27  \n",
      "4  Digital Wallet  In-store       2023-06-11  \n",
      "5     Credit Card       NaN       2023-03-31  \n",
      "6             NaN  Takeaway       2023-10-06  \n",
      "7            Cash       NaN       2023-10-28  \n",
      "8             NaN  Takeaway       2023-07-28  \n",
      "9             NaN  In-store       2023-12-31  \n"
     ]
    }
   ],
   "source": [
    "# For the Total Spent column, we will multiply ppu with quantity\n",
    "\n",
    "df['Total Spent'] = df['Price Per Unit'] * df['Quantity']\n",
    "\n",
    "\n",
    "#print((df['Total Spent'].sum())) \n",
    "\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecb4fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Items column, leave it as it is\n",
    "#items_mode = df['Item'].mode()\n",
    "\n",
    "#df['Item'].fillna(items_mode, inplace=True)\n",
    "\n",
    "#print(items_mode)\n",
    "#print(df['Item'].items_mode.sum()) # Prints 0 which means no erros or unknowns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87c5499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Payment Method leave it alone\n",
    "\n",
    "#Location leave it alone\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "9540\n"
     ]
    }
   ],
   "source": [
    "#Transaction Date we will drop all unknown\n",
    "df = df.dropna(subset=['Transaction Date'])\n",
    "\n",
    "print(df['Transaction Date'].isnull().sum())  # Should print 0\n",
    "print(df['Transaction Date'].count())        # See all unique values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e75ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_cafe_sales.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
